{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8db4d0d",
   "metadata": {
    "id": "d8db4d0d"
   },
   "source": [
    "# <center>Parallel computing: fundamentals </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056188b7",
   "metadata": {},
   "source": [
    "## =========================== Motivation ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90505381",
   "metadata": {
    "id": "90505381"
   },
   "source": [
    "\n",
    "\n",
    "### Moore's law\n",
    "Moore's law states that the number of transistors that compose an integrated circuit would roughly double every two years, that is, it grows exponentially.\n",
    "<img src=\"figures/parallelism_time.png\" alt=\"Moore\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Physical miniaturization limits and energy consumption\n",
    "A Si atom has a size of approximately $2\\times10^{-10}\\ $m, while a modern transistor has a size of $1\\times10^{-8}$ m. As the size of the transistor approaches the atomic scale the possibility of building the device is lost, as the number of available atoms is not enough to capture the required structure.<br/>\n",
    "<figure>\n",
    "    <img src=\"figures/Ga2O3Trans.png\" alt=\"Trans\" style=\"width: 500px\"/>\n",
    "    <figcaption align=\"center\">\n",
    "        <b>Source: https://news.cornell.edu/stories/2018/06/vertical-gallium-oxide-transistor-high-power-efficiency</b>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "On the other hand, as more transistors are closely packaged the power consumption per unit area and the heat production increase. It has been observed that these effects can be decreased substantially by replacing a single powerful compute core by several, less powerful cores that share the workload.  \n",
    "<img src=\"figures/power-curve.png\" alt=\"Power\" style=\"width: 600px\"/>\n",
    "\n",
    "### Memory access\n",
    "Though computing power is increasing at a rate of approx. 60\\% per year, the speed with which data can be accessed increases at a much lower rate (7\\% per year).\n",
    "<img src=\"figures/memory_access.png\" alt=\"Power\" style=\"width: 600px\"/>\n",
    "\n",
    "This means that if we access memory very often the processor spends a lot of idle time. To decrease the access to memory it is important to understand the hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0c27b",
   "metadata": {},
   "source": [
    "## ========== Concurrent, parallel, and distributed computing ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c787b",
   "metadata": {
    "id": "407c787b"
   },
   "source": [
    "## Concurrent computing\n",
    "Concurrency implies interruptibility. In concurrent computing, you have several tasks, but these tasks may not execute all the time because, from time to time, they need to wait for another task to finish. For example, a task od adding two numbers may have to wait for I/O operations to get the values it has to add and return the results.\n",
    "\n",
    "### Example: Pipeline in a processor\n",
    "A processor needs to carry out several steps every time it receives an instruction, and it usually has specialized units to carry out each step. For example:\n",
    "- Fetch the instruction (IF).\n",
    "- Decode the instruction (ID).\n",
    "- Execute the instruction (EX).\n",
    "- Read/write information in the memory (MEM).\n",
    "- Write the result back (WB).\n",
    "\n",
    "<figure>\n",
    "<img src=\"figures/Nopipeline.png\" style=\"width: 600px\"/>\n",
    "<figcaption align = \"center\"><span style=\"fontsize: 100px\">CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=140175</span></figcaption>\n",
    "</figure>\n",
    "    \n",
    "To prevent having its different units in an idle state while one of the units is carrying out its task, the work is pipelined:\n",
    "<figure>\n",
    "<img src=\"figures/Fivestagespipeline.png\" style=\"width: 450px\"/>\n",
    "<figcaption align = \"center\"><span style=\"fontsize: 100px\">CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=140175</span></figcaption>\n",
    "</figure>\n",
    "    \n",
    "Note that in a pipeline all units work at the same time, but do different jobs. We say that the processor is executing several jobs **concurrently**. \n",
    "    \n",
    "## Parallel computing\n",
    "In parallel computing, we have one or more tasks and use several computing units in the same device (node). Each of the computing units is capable of executing any task or part of a task, so we assign a whole task or part of a task to each unit. All computing units execute their assigned tasks at the same time, i.e. in *parallel*.\n",
    "\n",
    "<img src=\"figures/parallel_comp.png\" style=\"width: 350px\"/>\n",
    "\n",
    "## Distributed computing\n",
    "In distributed computing, we use several devices interconnected by a network. Each device can have one or more compute units. As in parallel computing, each device can execute tasks in parallel with the other, but the devices need now to communicate with one another to pass data between them through a network. As different devices might require to fetch or deliver data at particular moments, there has to be coordination in the communication between them. This coordination can be achieved by implementing a message-passing protocol.\n",
    "\n",
    "<img src=\"figures/distributed_comp.png\" style=\"width: 350px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47574fc",
   "metadata": {
    "id": "a47574fc"
   },
   "source": [
    "## ======================The CPU and Flynn's taxonomy ======================\n",
    "A central processing unit (CPU), or processor, is composed of 3 main parts: An arithmetic logic unit (ALU), or *core*, that performs arithmetic calculations on data. A memory unit that stores the instructions, the data to be processed, and the results of the computations, and a control unit that dictates which instructions to carry out next and what data to read from the memory.\n",
    "\n",
    "<img src=\"figures/CPU.png\" style=\"width: 400px\"/>\n",
    "\n",
    "The architectures used in parallel and distributed computing are extensions and variations of the CPU model that contain several compute units, some of which might share memory or a control unit. These devices are classified according to the way in which the compute units and the memory are connected among themselves. This classification is known as **Flynn's taxonomy**, proposed by Michael Flynn in its current form in 1972. A revision of Flynn's taxonomy was carried out later by Ralph Duncan to include pipelined vector processes. We present now some of the most common architectures.\n",
    "\n",
    "### Single instruction single data (SISD)\n",
    "In the SISD architecture, we have a single processor that executes instructions one at a time.\n",
    "\n",
    "<img src=\"figures/SISD.png\" style=\"width: 200px\"/>\n",
    "\n",
    "### Single instruction multiple data (SIMD)\n",
    "In this architecture, several cores share the same control unit. A single instruction is broadcasted to all the ALUs. The data is then partitioned and each processor executes the instruction using a different part of the data.\n",
    "\n",
    "<img src=\"figures/SIMD.png\" style=\"width: 500px\"/>\n",
    "\n",
    "### Multimple instruction multiple data (MIMD)\n",
    "This architecture consists of several processors, each one with its own control unit, so that they can perform different instructions in parallel. This is the most common architecture.\n",
    "\n",
    "<img src=\"figures/MIMD.png\" style=\"width: 700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47275993",
   "metadata": {
    "id": "47275993"
   },
   "source": [
    "## Processes and threads\n",
    "\n",
    "A **process** is an instance of a program that is assigned to a device, along with the data needed and access to the shared memory. A process consists of the following:\n",
    "- A process ID assigned by the operating system.\n",
    "- Access to a section of the memory to read/write data (virtual address space). The code and the data are located in the memory.\n",
    "- One or more *threads* that execute the code.\n",
    "- IO handles.\n",
    "\n",
    "\n",
    "A **thread**  is the part of a process that executes the instructions. It has a program counter, a set of registers, and memory (stack) assigned to it to store instructions and data locally.\n",
    "\n",
    "<img src=\"figures/process.png\" style=\"width: 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-interpretation",
   "metadata": {
    "id": "cosmetic-interpretation"
   },
   "source": [
    "## Fork-join model\n",
    "In the fork-join model, the code is divided into different regions. A region can be sequential or parallel, depending on the number of threads that are executed. In a sequential region, a single thread executes the code, while in a parallel region, multiple threads execute, usually the same code with different data.\n",
    "\n",
    "<img src=\"figures/fj_model.png\" style=\"width: 500px\"/>\n",
    "\n",
    "Sequential regions usually run code that cannot be parallelized because of strict dependencies between operations. Once a parallelizable region of the code is reached, a fork operation creates several threads and assigns a copy of the code, as well as a chunk of data, to each one. Once all threads have finished their jobs, a join operation retrieves the output data from each thread and destroys it, leaving a single thread in charge again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9132ca",
   "metadata": {
    "id": "fe9132ca"
   },
   "source": [
    "## ===================== Example of parallelism ===========================\n",
    "Now we proceed to look at a simple example of parallelism, in which we create multiple threads for a single process in order to perform a series of tasks in parallel.<br>\n",
    "\n",
    "Let's start by defining a simple task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a6628",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`task1.py`\n",
    "```python\n",
    "from time import sleep\n",
    "\n",
    "def task(n):\n",
    "    print('Starting task {0}...'.format(n))\n",
    "    sleep(1)\n",
    "    print('Task {0}: done'.format(n))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f91c5",
   "metadata": {
    "id": "de4f91c5"
   },
   "source": [
    "### Single process, single thread\n",
    "We now execute the task a couple of times and measure how much time it takes for the process to complete, using the single thread it creates by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157817e",
   "metadata": {
    "id": "0c705bc4",
    "outputId": "f404443f-6895-43cd-8a6a-d652661af9f2"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "`example1.py`\n",
    "```python\n",
    "from time import perf_counter\n",
    "from task1 import task\n",
    "    \n",
    "start_time = perf_counter() #Clock with the highest available resolution\n",
    "\n",
    "task(0)\n",
    "task(1)\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f7a41",
   "metadata": {
    "id": "bc0f7a41"
   },
   "source": [
    "### Single process, multiple threads\n",
    "Now, we proceed to ask the process to create more threads, and we assign to each one of them a single task to perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52834018",
   "metadata": {
    "id": "52834018"
   },
   "source": [
    "Two threads:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2e310",
   "metadata": {
    "id": "b30a8ae0",
    "outputId": "6bfee963-8990-4dda-8f06-60e56bf02cee"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "    \n",
    "`example2.py`\n",
    "```python\n",
    "from time import perf_counter\n",
    "from threading import Thread\n",
    "from task1 import task\n",
    "    \n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create two threads, each one with a task function\n",
    "t0 = Thread(target=task, args=(0,))\n",
    "t1 = Thread(target=task, args=(1,))\n",
    "\n",
    "# Start the threads\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd16a6",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51633",
   "metadata": {
    "id": "54b51633"
   },
   "source": [
    "### Exercise 1\n",
    "Repeat the previous example but using eight threads (Hint: the Thread objects can be stored in a python list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4bee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 exercises/exercise1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c490bf6",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc18b14",
   "metadata": {
    "id": "abc18b14"
   },
   "source": [
    "Note that in the previous examples when launching $n$ threads the time reduction is almost $n$-fold. However, this level of efficiency can only be attained as long as the following requirements are met:\n",
    "- The tasks can be performed in a parallel fashion, that is, the input of a task is independent of the output of all others. \n",
    "- There are enough computing units to carry out each task simultaneously.\n",
    "- The time it takes for a task to complete is much longer than the time it takes to create, start and join a thread.\n",
    "\n",
    "If you execute the previous code cell several times you might note also that the threads do not necessarily complete their tasks in order, and in some cases, a thread might finish even before others have been started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff92d9",
   "metadata": {
    "id": "f9ff92d9"
   },
   "source": [
    "### Race conditions\n",
    "We will now observe what happens when the result of one task depends on the actions taken by other tasks. To do this we take a simple example: incrementing the value of a global (shared) variable $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab139c94",
   "metadata": {
    "id": "a0d039b1",
    "outputId": "315927e7-6781-4fe9-80cb-60367af25a0e"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example3.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "x = 0\n",
    "\n",
    "def increment_variable(n):\n",
    "    global x\n",
    "        \n",
    "    sleep(1)\n",
    "    local_x = x\n",
    "    print(\"Task {0}: Adding 1 to x={1}\".format(n, x))\n",
    "    local_x += 1\n",
    "    x = local_x\n",
    "    print(\"Task {0}: Finished. x={1}\".format(n,x))\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "print(\"Initial x={0}\\n\".format(x))\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "for i in range(8):\n",
    "    increment_variable(i)\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"\\nFinal x={0}\".format(x))\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603605d",
   "metadata": {
    "id": "6603605d"
   },
   "source": [
    "The previous serial code works as expected, where the first task takes the current value of $x=0$, adds $1$ to obtain $x=1$, which is taken by the second task and is incremented to $2$ and so on, until the final task takes a $7$ and adds $1$ to get the final correct result $x=8$, in approximately 8 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc731e",
   "metadata": {
    "id": "81a3c5fe",
    "outputId": "9e25dcd9-dfe6-48e1-ed07-c29913f89aac"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example4.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "from threading import Thread\n",
    "    \n",
    "x = 0\n",
    "\n",
    "def increment_variable(n):\n",
    "    global x\n",
    "        \n",
    "    sleep(1)\n",
    "    local_x = x\n",
    "    print(\"Task {0}: Adding 1 to x={1}\".format(n, x))\n",
    "    local_x += 1\n",
    "    x = local_x\n",
    "    print(\"Task {0}: Finished. x={1}\".format(n,x))\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "print(\"Initial x={0}\\n\".format(x))\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create 8 threads, each one with a task function\n",
    "threads = []\n",
    "for i in range(8):\n",
    "    threads.append(Thread(target=increment_variable, args=(i,)))\n",
    "\n",
    "# Start the threads\n",
    "for thr in threads:\n",
    "    thr.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "for thr in threads:\n",
    "    thr.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"\\nFinal x={0}\".format(x))\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb229852",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe831b",
   "metadata": {
    "id": "5afe831b"
   },
   "source": [
    "By executing the previous cell multiple times you might find, perhaps with surprise, that in some cases the final result $x<8$ ! For example, we might observe the following output:<br><br>\n",
    "\n",
    "<pre><code>Initial x=0\n",
    "\n",
    "Task 0: Adding 1 to x=0Task 1: Adding 1 to x=0\n",
    "Task 1: Finished. x=1\n",
    "Task 2: Adding 1 to x=1\n",
    "Task 2: Finished. x=2\n",
    "Task 5: Adding 1 to x=2\n",
    "Task 5: Finished. x=3\n",
    "Task 3: Adding 1 to x=3\n",
    "Task 3: Finished. x=4\n",
    "Task 4: Adding 1 to x=4\n",
    "Task 4: Finished. x=5\n",
    "\n",
    "Task 0: Finished. x=1\n",
    "Task 6: Adding 1 to x=1\n",
    "Task 6: Finished. x=2\n",
    "Task 7: Adding 1 to x=2\n",
    "Task 7: Finished. x=3\n",
    "\n",
    "Final x=3\n",
    "Time: 1.0039066870231181\n",
    "</code></pre>\n",
    "\n",
    "We obtained the result in 1/8 of the time it took the serial code to run, but the result is incorrect. Why is this? <br>\n",
    "\n",
    "By looking carefully at the output we see that threads 0 and 1 started first and both took as input an initial value $x=0$, added $1$, and wrote the result $1$ back to $x$. Note that by this point two tasks have been executed but $x=1$, when it should have been $2$. In a similar way, threads 2 and 6 take $x$ as input when its value is $1$ and write back a value $x=2$, so 4 tasks have been executed already and the result is $x=2$, when it should have been $4$.<br>\n",
    "\n",
    "The problem lies then in the possibility of having more than one thread updating the shared variable at the same time. This kind of problem is called a *race condition*, as the threads compete to get first to a shared variable and modify it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1032419",
   "metadata": {
    "id": "e1032419"
   },
   "source": [
    "### Thread lock\n",
    "In order to prevent more than one thread from accessing the same memory space at the same time, we can *lock* a section of code. Only a single thread can be executing a *locked* section of code at the same time, meaning that the other threads have to wait until the current thread is finished to be able to execute it themselves.<br>\n",
    "\n",
    "We will create a Lock object and use it to lock the code inside the increment_variable function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aeec6",
   "metadata": {
    "id": "fb3e9aa4",
    "outputId": "624f0d7d-4d90-4405-d147-c2eba3f84c88"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example5.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "from threading import Thread, Lock\n",
    "\n",
    "x = 0\n",
    "\n",
    "def increment_variable(n, lock):\n",
    "    global x\n",
    "    \n",
    "    lock.acquire() #Start of the locked region\n",
    "    \n",
    "    sleep(1)\n",
    "    local_x = x\n",
    "    print(\"Task {0}: Adding 1 to x={1}\".format(n, x))\n",
    "    local_x += 1\n",
    "    x = local_x\n",
    "    print(\"Task {0}: Finished. x={1}\".format(n,x))\n",
    "\n",
    "    lock.release() #End of the locked region\n",
    "    \n",
    "#------------------------------------------------------------------\n",
    "print(\"Initial x={0}\\n\".format(x))\n",
    "\n",
    "#create Lock object\n",
    "lock = Lock()\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create 8 threads, each one with a task function\n",
    "threads = []\n",
    "for i in range(8):\n",
    "    threads.append(Thread(target=increment_variable, args=(i,lock)))\n",
    "\n",
    "# Start the threads\n",
    "for thr in threads:\n",
    "    thr.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "for thr in threads:\n",
    "    thr.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"\\nFinal x={0}\".format(x))\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4ac65",
   "metadata": {
    "id": "d5d4ac65"
   },
   "source": [
    "We see now that the code gives the correct output every time, but it takes the same time as the serial code, which beats the purpose of our parallelization. The reason why this happens is that we have included all the code of the function in the locked region, and the threads have to wait for a full second every time another thread enters the locked region. If we manage to keep just the critical section of code where the race condition is present, we might get back some of the efficiency of our parallelization.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0beb8",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90439df5",
   "metadata": {
    "id": "90439df5"
   },
   "source": [
    "### Exercise 2\n",
    "Taking out of the locked region all the code that does not present a race condition problem and reduce the execution time, while ensuring the correctness of the result! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 exercises/exercise2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739979b",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c813ed-6a60-4706-9530-15bcaaae90d2",
   "metadata": {},
   "source": [
    "## ============================= Performance =============================\n",
    "\n",
    "### Terms\n",
    "- **$N$:** Number of software threads.\n",
    "- **$P$:** Number of compute units.\n",
    "- **$T_P$:** Execution time using $P$ parallel compute units.\n",
    "- **$T_{\\infty}$:** Execution time when $P\\rightarrow\\infty$.\n",
    "- **$T_{sec}$:** Sequential execution time. It refers to the time that takes to execute the parts of the program which are not parallelizable.\n",
    "- **$T_{oh}$:** Overhead time. It refers to the extra computing time invested in tasks like creating and destroying threads, partitioning, copying and loading data for thread use, etc. \n",
    "\n",
    "Note that $N$ and $P$ are different concepts. If $N<P$ then some of the compute units remain idle during the computation. If $N=P$, each thread runs on a compute unit (hardware thread). If $N>P$, some threads will have to wait until a compute unit becomes available to execute them.<br>\n",
    "\n",
    "### Performance metrics for parallelism\n",
    "- **Span:** $T_{\\infty}$. Execution time is the smallest when the maximum number of threads that can run the program simultaneously can do so on a separate compute unit: $P\\rightarrow\\infty$, then $T_P\\geq T_{\\infty}$.\n",
    "- **Speedup:** $T_1/T_P$. At most, speedup grows linearly with $P$: $T_1/T_P=\\Theta(P)$. \n",
    "- **Parallelism:** $T_1/T_\\infty$. Is the maximum theoretical speedup.\n",
    "- **Work:** $PT_P$. It is minimum when $P=1$, so $T_P\\geq T_1/P$.\n",
    "- **Efficiency:** $T_1/(PT_P)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cbb2d-d78f-4837-bee8-1dbf59f03303",
   "metadata": {},
   "source": [
    "### Ahmdal's argument\n",
    "Define the serial fraction:\n",
    "$$\\gamma=\\frac{T_{sec}}{T_1},$$\n",
    "then\n",
    "$$T_P=T_{sec}+\\frac{1}{P}(T_1-T_{sec})+T_{oh}$$\n",
    "which, in terms of the serial fraction gives\n",
    "$$T_P=T_1\\left(\\gamma+\\frac{1}{P}(1-\\gamma)+\\gamma_{oh}\\right),$$\n",
    "where $\\gamma_{oh}=T_{oh}/T_1$.<br>\n",
    "\n",
    "This means that the speedup $S(P)$ when using $P$ computing units is\n",
    "$$S(P)=\\frac{1}{\\gamma+(1-\\gamma)/P+\\gamma_{oh}}.$$\n",
    "Lineal speedup is attained when $\\gamma\\rightarrow 0$ and $\\gamma_{oh}\\rightarrow 0$.<br>\n",
    "\n",
    "#### Plotting the theoretical speedup\n",
    "Here, $n$ represents the size of the problem. In the following plot, the size of both the sequential and parallel regions grows as $n$:\n",
    "\n",
    "<img src=\"figures/speedup-1.png\" width=600/>\n",
    "\n",
    "In the next plot, the size of the sequential region remains constant while the size of the parallel region grows as $n$:\n",
    "\n",
    "<img src=\"figures/speedup1-1.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d80f1-a498-4ee3-ae8f-ab0beae2cae2",
   "metadata": {},
   "source": [
    "## ========================= Speedup experiment =========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15e8e3-1de3-4d16-9f35-9dcfb1284cb3",
   "metadata": {},
   "source": [
    "### Sequential program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cb57f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`seq_add.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "# Sequential vector addition\n",
    "def vector_sum(v1, v2):\n",
    "    try: \n",
    "        if len(v1) != len(v2):\n",
    "            raise Exception('The two vectors do not have the same number of elements.')\n",
    "        res = [0 for i in range(len(v1))]\n",
    "        \n",
    "        for i in range(len(v1)):\n",
    "            sleep(delay)\n",
    "            res[i] = v1[i] + v2[i]\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        \n",
    "# Measure the average execution time of a sequential run\n",
    "def seq_run(v1, v2, Ntrials):\n",
    "    start_time = perf_counter()\n",
    "    for i in range(Ntrials):\n",
    "        res = vector_sum(v1,v2)\n",
    "    end_time = perf_counter()\n",
    "        \n",
    "    return res, (end_time-start_time)/Ntrials\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8df28c-022d-4f5b-928c-92375528481b",
   "metadata": {},
   "source": [
    "### Parallel program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d382e2e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`paral_add.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "from threading import Thread\n",
    "\n",
    "# Add vector's elements from ini to fin-1\n",
    "def add(x, y, z, ini, fin):\n",
    "    for i in range(ini, fin):\n",
    "        sleep(delay)\n",
    "        z[i] = x[i] + y[i]\n",
    "\n",
    "# Parallelized vector addition\n",
    "def par_vector_sum(v1, v2, n_thr):\n",
    "    try: \n",
    "        if len(v1) != len(v2):\n",
    "            raise Exception('The two vectors do not have the same number of elements.')\n",
    "        res = [0 for i in range(len(v1))]\n",
    "        \n",
    "        n_thr = min(n_thr, len(v1)) #Number of threds <= length of the vectors\n",
    "        \n",
    "        chunk_size = len(v1) // n_thr + 1 #No. of tasks for each thread\n",
    "        \n",
    "        #Create the threads\n",
    "        threads = []\n",
    "        for i in range(n_thr):\n",
    "            ini = i*chunk_size\n",
    "            fin = min(ini + chunk_size, len(v1))\n",
    "            threads.append(Thread(target=add, args=(v1, v2, res, ini, fin)))\n",
    "        \n",
    "        # Start the threads\n",
    "        for thr in threads:\n",
    "            thr.start()\n",
    "\n",
    "        # Wait for the threads to complete\n",
    "        for thr in threads:\n",
    "            thr.join()\n",
    "        return res, n_thr\n",
    "    \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    \n",
    "# Measure the average execution time of a parallel run\n",
    "def par_run(v1, v2, Ntrials, n_thr):\n",
    "    start_time = perf_counter()\n",
    "    for i in range(Ntrials):\n",
    "        res, n_thr = par_vector_sum(v1,v2,n_thr)\n",
    "    end_time = perf_counter()\n",
    "    \n",
    "    return res, (end_time-start_time)/Ntrials\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2e186-c7f5-4684-91ea-538f3c2290a9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ffddf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example6.py`\n",
    "```python\n",
    "from seq_add import seq_run\n",
    "\n",
    "# Sequential test\n",
    "\n",
    "# Declare and initialize the input\n",
    "sz = 1000\n",
    "v1 = [1 for i in range(sz)]\n",
    "v2 = [2 for i in range(sz)]\n",
    "\n",
    "Ntrials = 100\n",
    "\n",
    "res, seq_time = seq_run(v1, v2, Ntrials)\n",
    "\n",
    "##Check result\n",
    "assert res == [3 for i in range(sz)]\n",
    "\n",
    "print(\"Secuential addition.\")\n",
    "print(\"Time: {0:.7f}\".format(seq_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef049ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ceb891",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example7.py`\n",
    "```python\n",
    "from sys import argv\n",
    "from paral_add import par_run\n",
    "\n",
    "# Parallel test\n",
    "\n",
    "code, seq_time = argv\n",
    "seq_time = float(seq_time)\n",
    "\n",
    "# Declare and initialize the input\n",
    "sz = 1000\n",
    "v1 = [1 for i in range(sz)]\n",
    "v2 = [2 for i in range(sz)]\n",
    "\n",
    "Ntrials = 100\n",
    "\n",
    "#Number of threads\n",
    "nt = 4\n",
    "res, par_time = par_run(v1, v2, Ntrials, nt)\n",
    "\n",
    "##Check result\n",
    "assert res == [3 for i in range(sz)]\n",
    "\n",
    "print(\"No. of threds: {0}\".format(nt))\n",
    "print(\"Time: {0:.7f}\".format(par_time))\n",
    "print(\"Speedup: {0:.3f}\".format(seq_time/par_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49230ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/example7.py 0.0770231"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdabc541-68fc-471e-883d-b42308eb2a2a",
   "metadata": {},
   "source": [
    "### Plot speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b13a67",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`speedup.py`\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from seq_add import seq_run\n",
    "from paral_add import par_run\n",
    "from matplotlib import rc\n",
    "rc('text',usetex=True)\n",
    "\n",
    "# Declare and initialize the input\n",
    "sz = 1000\n",
    "v1 = [1 for i in range(sz)]\n",
    "v2 = [2 for i in range(sz)]\n",
    "Ntrials = 100\n",
    "\n",
    "#Perform the computations for  different number of cores\n",
    "res, seq_time = seq_run(v1, v2, Ntrials)\n",
    "\n",
    "speedups = []\n",
    "procs = [i for i in range(1,7)]\n",
    "for P in procs:\n",
    "    res, par_time = par_run(v1, v2, Ntrials, P)\n",
    "    speedups.append(seq_time/par_time)\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ab68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 code/speedup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d135924-f8ea-4769-8fe1-eba8eb238c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "procs = []\n",
    "speedups = []\n",
    "with open(\"code/spdup_data.dat\", \"r\") as ifile:\n",
    "    for line in ifile:\n",
    "        v = list(map(float, line.split()))\n",
    "        procs.append(v[0])\n",
    "        speedups.append(v[1])\n",
    "\n",
    "#Plot data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.plot(procs, speedups, marker='o')\n",
    "ax.set_xlabel(r\"$P$\", fontsize=20)\n",
    "ax.set_ylabel(r\"$S(P)$\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df37cb",
   "metadata": {},
   "source": [
    "## ================ Exercise: Counting 3s =================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d2486",
   "metadata": {},
   "source": [
    "**Problem:** We have a list of integers ```l``` which contains numbers between 0 and 3. We are interested in counting the number of 3s contained in the list, so for example, if the list is:<br>\n",
    "\n",
    "```3,1,2,0,1,3,2,3,1,2,0```\n",
    "\n",
    "then the result is 3, because there are three 3s in the list.<br>\n",
    "\n",
    "The following code counts the number of 3s contained on a list ```l```$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf7756",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "`count_3s_seq.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "#Read the list of numbers from a file\n",
    "def read_list():\n",
    "    l = []\n",
    "    with open(\"exercises/list.dat\",\"r\") as infile:\n",
    "        l = list(map(int,infile.read().split()))\n",
    "    return l\n",
    "\n",
    "#Count the number of 3s in list l and store the result on count\n",
    "def count3s(l, count):\n",
    "    for i in range(len(l)):\n",
    "        sleep(1.e-3)\n",
    "        if l[i] == 3:\n",
    "            count[0] += 1  \n",
    "            \n",
    "#------------------------------------------------------\n",
    "l = read_list()\n",
    "    \n",
    "count = [0]\n",
    "t_start = perf_counter()\n",
    "count3s(l, count)\n",
    "t_stop = perf_counter()\n",
    "\n",
    "print(\"Time: {0} s.\".format(t_stop-t_start))\n",
    "print(\"Number of 3s counted: {0}\".format(count[0]))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 exercises/count_3s_seq.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4d86c",
   "metadata": {},
   "source": [
    "**Note** that the ```count3s``` function sleeps for a milisecond every time it checks if a number is a 3 or not. We do this because the task of checking a number is very small and python's threading module is not very optimized, so we artificially inflate the size of the task to observe a decrease in execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69388e8f",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "The goal is to parallelize the task of counting 3s in a list ```l```. To do this we will create 4 threads and split ```l``` in 4 chuncks of approximate size ```(len(l)+1)//4```. Each thread will be given a different chink and it will count the number of 3s in it's corresponding chunk. The result that each thread obtains will be added to a variable ```count``` where the result with the total number of 3s will be stored.<br>\n",
    "\n",
    "The following figure shows how the list has been split between the four threads:\n",
    "\n",
    "<img src=\"figures/listl.png\" width=400>\n",
    "\n",
    "Note that in some cases the last thread will have a chunck size different to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d2e42",
   "metadata": {},
   "source": [
    "### Hints:\n",
    "- Set the size of the chink as ```(len(l)+1)//4```.\n",
    "- One can take a slice of a python list ```l``` by writing ```l[ini:fin]```, where ```ini``` refers to the index of the first element of the chunk, and ```fin``` to the index after the last element of the chunk.\n",
    "- Create two functions: ```count3s(l, count)``` which receives the list and the global counter and creates and launches the threads, and ```count3s_thread(chunk, count, lock)``` which receives a chunk of the list, the global counter, and a lock, goes throught the chunk and counts how many 3s does it find in it, and finally adds this number to the global result.\n",
    "- Remember to avoid race conditions by using a lock. Create a private counter within the thread function to acumulate the partial result. Then, accumulate the partial result to the global result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 8 python3 exercises/count_3s_par.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
